{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who will survive in Titanic?\n",
    "\n",
    "When the Titanic sank, 1502 of the 2224 passengers and crew were killed. One of the main reasons for this high level of casualties was the lack of lifeboats on this self-proclaimed \"unsinkable\" ship.\n",
    "\n",
    "Those that have seen the movie know that some individuals were more likely to survive the sinking (lucky Rose) than others (poor Jack). Since we got the data about the passengers, it's a good idea to apply machine learning techniques to predict a passenger's chance of surviving using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the train and test datasets to create two DataFrames\n",
    "#train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "#Print the `head` of the train and test dataframes\n",
    "#print(train.head())\n",
    "#print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".describe() summarizes the columns/features of the DataFrame, including the count of observations, mean, max and so on. Another useful trick is to look at the dimensions of the DataFrame. This is done by requesting the .shape attribute of your DataFrame object. (ex. your_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
       "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
       "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the qualtiles of \"Age\" variable, there are \"NaN\"s, which means there are probably lots of Age information missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000         NaN    0.000000    0.000000         NaN\n",
       "50%    1100.500000    3.000000         NaN    0.000000    0.000000         NaN\n",
       "75%    1204.750000    3.000000         NaN    1.000000    0.000000         NaN\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (891, 12)\n",
      "test shape: (418, 11)\n",
      "Age counts: 714\n"
     ]
    }
   ],
   "source": [
    "print \"train shape:\", train.shape\n",
    "print \"test shape:\",  test.shape\n",
    "print \"Age counts:\", train[\"Age\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set has 891 observations and 12 variables, count for Age is 714, which means there are 891- 714 = 177 age variable missing. So we shall fill in the \"NaN\" with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0\n"
     ]
    }
   ],
   "source": [
    "print train[\"Age\"].median()\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64 \n",
      "\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Passengers that survived vs passengers that passed away\n",
    "print (train[\"Survived\"].value_counts()), \"\\n\"\n",
    "# As proportions\n",
    "print (train[\"Survived\"].value_counts(normalize= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males that survived vs males that passed away\n",
      "0    468\n",
      "1    109\n",
      "Name: Survived, dtype: int64\n",
      "0    0.811092\n",
      "1    0.188908\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (\"Males that survived vs males that passed away\")\n",
    "print(train['Survived'][train['Sex']=='male'].value_counts())\n",
    "\n",
    "# Normalized male survival\n",
    "print(train['Survived'][train['Sex']=='male'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Females that survived vs Females that passed away\n",
      "1    233\n",
      "0     81\n",
      "Name: Survived, dtype: int64\n",
      "1    0.742038\n",
      "0    0.257962\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (\"Females that survived vs Females that passed away\")\n",
    "print(train['Survived'][train['Sex']=='female'].value_counts())\n",
    "\n",
    "# Normalized female survival\n",
    "print(train['Survived'][train['Sex']=='female'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized Survival Rates for passengers under 18\n",
      "1    0.539823\n",
      "0    0.460177\n",
      "Name: Survived, dtype: float64 \n",
      "\n",
      "normalized Survival Rates for passengers 18 or older\n",
      "0    0.638817\n",
      "1    0.361183\n",
      "Name: Survived, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Create the column Child and assign to 'NaN'\n",
    "train[\"Child\"] = 0\n",
    "train[\"Child\"][train[\"Age\"]<18] = 1\n",
    "train[\"Child\"][train[\"Age\"]>= 18] = 0\n",
    "# Assign 1 to passengers under 18, 0 to those 18 or older. Print the new column.\n",
    "#print (train['Child'])\n",
    "\n",
    "print \"normalized Survival Rates for passengers under 18\"\n",
    "print(train[\"Survived\"][train[\"Child\"] == 1].value_counts(normalize = True)), \"\\n\"\n",
    "\n",
    "print \"normalized Survival Rates for passengers 18 or older\"\n",
    "\n",
    "print(train[\"Survived\"][train[\"Child\"] == 0].value_counts(normalize = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    646\n",
      "1    168\n",
      "2     77\n",
      "Name: Embarked, dtype: int64\n",
      "0    646\n",
      "1    168\n",
      "2     77\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print train[\"Embarked\"].value_counts()\n",
    "# Impute the Embarked variable\n",
    "train[\"Embarked\"] = train['Embarked'].fillna('S')\n",
    "\n",
    "# Convert the Embarked classes to integer form\n",
    "\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n",
    "print train[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      0\n",
      "8      1\n",
      "9      1\n",
      "10     1\n",
      "11     1\n",
      "12     0\n",
      "13     0\n",
      "14     1\n",
      "15     1\n",
      "16     0\n",
      "17     0\n",
      "18     1\n",
      "19     1\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     0\n",
      "24     1\n",
      "25     1\n",
      "26     0\n",
      "27     0\n",
      "28     1\n",
      "29     0\n",
      "      ..\n",
      "861    0\n",
      "862    1\n",
      "863    1\n",
      "864    0\n",
      "865    1\n",
      "866    1\n",
      "867    0\n",
      "868    0\n",
      "869    0\n",
      "870    0\n",
      "871    1\n",
      "872    0\n",
      "873    0\n",
      "874    1\n",
      "875    1\n",
      "876    0\n",
      "877    0\n",
      "878    0\n",
      "879    1\n",
      "880    1\n",
      "881    0\n",
      "882    1\n",
      "883    0\n",
      "884    0\n",
      "885    1\n",
      "886    0\n",
      "887    1\n",
      "888    1\n",
      "889    0\n",
      "890    0\n",
      "Name: Sex, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Convert the male and female groups to integer form\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train['Sex'][train['Sex'] == 'female'] = 1\n",
    "print (train['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**target** = train[\"Survived\"].values\n",
    "\n",
    "**features** = train[[\"Sex\", \"Age\"]].values\n",
    "\n",
    "**my_tree** = tree.DecisionTreeClassifier()\n",
    "\n",
    "**my_tree** = my_tree.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  Child  \n",
      "0         A/5 21171   7.2500   NaN        S    0.0  \n",
      "1          PC 17599  71.2833   C85        C    0.0  \n",
      "2  STON/O2. 3101282   7.9250   NaN        S    0.0  \n",
      "3            113803  53.1000  C123        S    0.0  \n",
      "4            373450   8.0500   NaN        S    0.0  \n"
     ]
    }
   ],
   "source": [
    "# Print the train data to see the available features\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Importances: Pclass', 0.12063996872930596, 'Sex', 0.31274009040120898, 'Age', 0.24527199349611564, 'Fare', 0.32134794737336941)\n",
      "0.977553310887\n"
     ]
    }
   ],
   "source": [
    "# Create the target and features numpy arrays: target, features_one\n",
    "target = train['Survived'].values\n",
    "features_one = train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "\n",
    "# Fit your first decision tree: my_tree_one\n",
    "my_tree_one = tree.DecisionTreeClassifier()\n",
    "my_tree_one = my_tree_one.fit(features_one, target)\n",
    "\n",
    "# Look at the importance and score of the included features\n",
    "print(\"Importances: \"  \"Pclass\", my_tree_one.feature_importances_[0], \"Sex\", my_tree_one.feature_importances_[1], \"Age\", my_tree_one.feature_importances_[2], \"Fare\", my_tree_one.feature_importances_[3])\n",
    "print(my_tree_one.score(features_one, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  418.000000  418.000000  418.000000  418.000000\n",
      "mean   1100.500000    2.265550   29.599282    0.447368    0.392344   35.576535\n",
      "std     120.810458    0.841838   12.703770    0.896760    0.981429   55.850103\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   23.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   35.750000    1.000000    0.000000   31.471875\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Impute the missing value with the median\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "print test.head()\n",
    "test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n",
    "test[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\n",
    "test[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n",
    "test[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())\n",
    "print test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Survived\n",
      "892          0\n",
      "893          0\n",
      "894          1\n",
      "895          1\n",
      "896          1\n",
      "897          0\n",
      "898          0\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          1\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          1\n",
      "910          1\n",
      "911          0\n",
      "912          0\n",
      "913          1\n",
      "914          1\n",
      "915          0\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          1\n",
      "920          1\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         0\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         1\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         0\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "(418, 1)\n",
      "      Survived\n",
      "892          0\n",
      "893          0\n",
      "894          1\n",
      "895          1\n",
      "896          1\n",
      "897          0\n",
      "898          0\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          1\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          1\n",
      "910          1\n",
      "911          0\n",
      "912          0\n",
      "913          1\n",
      "914          1\n",
      "915          0\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          1\n",
      "920          1\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         0\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         1\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         0\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract the features from the test set: Pclass, Sex, Age, and Fare.\n",
    "test_features = test[['Pclass', 'Sex', 'Age', 'Fare']].values\n",
    "\n",
    "# Make your prediction using the test set\n",
    "my_prediction = my_tree_one.predict(test_features)\n",
    "\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_one.csv\", index_label = [\"PassengerId\"])\n",
    "print(my_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your submission scored 0.72249**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control the Overfitting\n",
    "\n",
    "In DecisionTreeRegressor, the depth of our model is defined by two parameters: - the max_depth parameter determines when the splitting up of the decision tree stops. - the min_samples_split parameter monitors the amount of observations in a bucket. If a certain threshold is not reached (e.g minimum 10 passengers) no further splitting can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: Q",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ef95455a6e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmy_tree_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmy_tree_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_tree_two\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_two\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#Print the score of the new decison tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xuemingli/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xuemingli/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xuemingli/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: Q"
     ]
    }
   ],
   "source": [
    "# Create a new array with the added features: features_two\n",
    "features_two = train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", 'SibSp', 'Parch', 'Embarked']].values\n",
    "#print (features_two)\n",
    "\n",
    "#Control overfitting by setting \"max_depth\" to 10 and \"min_samples_split\" to 5 : my_tree_two\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "\n",
    "my_tree_two = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split, random_state = 1)\n",
    "my_tree_two = my_tree_two.fit(features_two, target)\n",
    "\n",
    "#Print the score of the new decison tree\n",
    "print my_tree_two.feature_importances_\n",
    "print (my_tree_two.score(features_two,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/xuemingli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "test[\"Embarked\"] = test['Embarked'].fillna('S')\n",
    "\n",
    "# Convert the Embarked classes to integer form\n",
    "\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 34.5 0 ..., 0 0 2]\n",
      " [3 47.0 1 ..., 1 0 0]\n",
      " [2 62.0 0 ..., 0 0 2]\n",
      " ..., \n",
      " [3 38.5 0 ..., 0 0 0]\n",
      " [3 27.0 0 ..., 0 0 0]\n",
      " [3 27.0 0 ..., 1 1 1]]\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before exploiting the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3b8d1efefdae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Make your prediction using the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmy_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_tree_two\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mPassengerId\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xuemingli/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xuemingli/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             raise NotFittedError(\"Estimator not fitted, \"\n\u001b[0m\u001b[1;32m    362\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before exploiting the model."
     ]
    }
   ],
   "source": [
    "# Extract the features from the test set: Pclass, Sex, Age, and Fare.\n",
    "test_features = test[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", 'SibSp', 'Parch', 'Embarked']].values\n",
    "\n",
    "print test_features\n",
    "# Make your prediction using the test set\n",
    "my_prediction = my_tree_two.predict(test_features)\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_two.csv\", index_label = [\"PassengerId\"])\n",
    "print(my_solution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your submission scored 0.76077**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature-engineering##\n",
    "\n",
    "A valid assumption is that larger families need more time to get together on a sinking ship, and hence have lower probability of surviving. Family size is determined by the variables SibSp and Parch, which indicate the number of family members a certain passenger is traveling with. So when doing feature engineering, you add a new variable family_size, which is the sum of SibSp and Parch plus one (the observation itself), to the test and train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979797979798\n"
     ]
    }
   ],
   "source": [
    "# Create train_two with the newly defined feature\n",
    "train_two = train.copy()\n",
    "train_two[\"family_size\"] = train['SibSp'] + train['Parch']+1\n",
    "\n",
    "# Create a new feature set and add the new feature\n",
    "features_three = train_two[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", 'family_size']].values\n",
    "\n",
    "# Define the tree classifier, then fit the model\n",
    "my_tree_three = tree.DecisionTreeClassifier()\n",
    "my_tree_three = my_tree_three.fit(features_three, target)\n",
    "\n",
    "# Print the score of this decision tree\n",
    "print(my_tree_three.score(features_three, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Survived\n",
      "892          0\n",
      "893          0\n",
      "894          1\n",
      "895          1\n",
      "896          0\n",
      "897          0\n",
      "898          0\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          1\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          1\n",
      "910          1\n",
      "911          0\n",
      "912          1\n",
      "913          1\n",
      "914          1\n",
      "915          0\n",
      "916          0\n",
      "917          0\n",
      "918          1\n",
      "919          1\n",
      "920          1\n",
      "921          1\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         1\n",
      "1285         0\n",
      "1286         1\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         1\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         1\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "(418, 1)\n",
      "      Survived\n",
      "892          0\n",
      "893          0\n",
      "894          1\n",
      "895          1\n",
      "896          0\n",
      "897          0\n",
      "898          0\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          1\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          1\n",
      "910          1\n",
      "911          0\n",
      "912          1\n",
      "913          1\n",
      "914          1\n",
      "915          0\n",
      "916          0\n",
      "917          0\n",
      "918          1\n",
      "919          1\n",
      "920          1\n",
      "921          1\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         1\n",
      "1285         0\n",
      "1286         1\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         1\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         1\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract the features from the test set: Pclass, Sex, Age, and Fare.\n",
    "test_two = test.copy()\n",
    "test_two[\"family_size\"] = test['SibSp'] + test['Parch']+1\n",
    "test_features = test_two[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", 'family_size']].values\n",
    "# Make your prediction using the test set\n",
    "my_prediction = my_tree_three.predict(test_features)\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId =np.array(test_two[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_three.csv\", index_label = [\"PassengerId\"])\n",
    "print(my_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your submission scored 0.62679**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    " \n",
    "Random Forest technique handles the overfitting problem you faced with decision trees. It grows multiple (very deep) classification trees using the training set. At the time of prediction, each tree is used to come up with a prediction and every outcome is counted as a vote. For example, if you have trained 3 trees with 2 saying a passenger in the test set will survive and 1 says he will not, the passenger will be classified as a survivor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the `RandomForestClassifier`\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: Q",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-996fe52fdeb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Building and fitting my_forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmy_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Print the score of the fitted random forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xuemingli/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xuemingli/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: Q"
     ]
    }
   ],
   "source": [
    "# We want the Pclass, Age, Sex, Fare,SibSp, Parch, and Embarked variables\n",
    "features_forest = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# Building and fitting my_forest\n",
    "forest = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators = 100, random_state = 1)\n",
    "my_forest = forest.fit(features_forest, target)\n",
    "\n",
    "# Print the score of the fitted random forest\n",
    "print(my_forest.score(features_forest, target))\n",
    "\n",
    "# Compute predictions on our test set features then print the length of the prediction vector\n",
    "test_features = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "pred_forest = my_forest.predict(test_features)\n",
    "PassengerId =np.array(test_two[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(pred_forest, PassengerId, columns = [\"Survived\"])\n",
    "print \"Check that your data frame has 418 entries\"\n",
    "print(my_solution.shape)\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_four.csv\", index_label = [\"PassengerId\"])\n",
    "print my_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before `feature_importances_`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-32a3e6b9d088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Request and print the `.feature_importances_` attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_tree_two\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Compute and print the mean accuracy score for both models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xuemingli/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfeature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \"\"\"\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             raise NotFittedError(\"Estimator not fitted, call `fit` before\"\n\u001b[0m\u001b[1;32m    499\u001b[0m                                  \" `feature_importances_`.\")\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before `feature_importances_`."
     ]
    }
   ],
   "source": [
    "#Request and print the `.feature_importances_` attribute\n",
    "print(my_tree_two.feature_importances_)\n",
    "print(my_forest.feature_importances_)\n",
    "\n",
    "#Compute and print the mean accuracy score for both models\n",
    "print(my_tree_two.score(features_two, target))\n",
    "print(my_forest.score(features_forest, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature was \"Sex\", but it was more significant for \"my_tree_two\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your submission scored 0.75598**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892255892256\n",
      "Check that your data frame has 418 entries\n",
      "(418, 1)\n",
      "      Survived\n",
      "892          0\n",
      "893          0\n",
      "894          1\n",
      "895          0\n",
      "896          0\n",
      "897          0\n",
      "898          0\n",
      "899          1\n",
      "900          0\n",
      "901          1\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          0\n",
      "906          0\n",
      "907          1\n",
      "908          0\n",
      "909          0\n",
      "910          0\n",
      "911          0\n",
      "912          1\n",
      "913          1\n",
      "914          1\n",
      "915          1\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          0\n",
      "920          1\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         1\n",
      "1283         1\n",
      "1284         1\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         1\n",
      "1294         1\n",
      "1295         1\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         1\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         0\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "0.892255892256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# We want the Pclass, Age, Sex, Fare,SibSp, Parch, and Embarked variables\n",
    "features_svc = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# Building and fitting my_forest\n",
    "clf = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "my_pred = clf.fit(features_svc, target)\n",
    "\n",
    "# Print the score of the fitted random forest\n",
    "print(my_pred.score(features_svc, target))\n",
    "\n",
    "# Compute predictions on our test set features then print the length of the prediction vector\n",
    "tests_svc = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "pred_svc = clf.predict(tests_svc)\n",
    "PassengerId =np.array(test_two[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(pred_svc, PassengerId, columns = [\"Survived\"])\n",
    "print \"Check that your data frame has 418 entries\"\n",
    "print(my_solution.shape)\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_svc.csv\", index_label = [\"PassengerId\"])\n",
    "print my_solution\n",
    "\n",
    "#Compute and print the mean accuracy score for both models\n",
    "print(clf.score(features_two, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
